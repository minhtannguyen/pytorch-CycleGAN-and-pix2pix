{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.debugger import Tracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64 # input batch size for training (default: 64)\n",
    "        self.test_batch_size = 100 # input batch size for testing (default: 100)\n",
    "        self.epochs = 10 # number of epochs to train (default: 10)\n",
    "        self.lr = 0.01 # learning rate (default: 0.01)\n",
    "        self.momentum = 0.5 # SGD momentum (default: 0.5)\n",
    "        self.no_cuda = False # disables CUDA training if True\n",
    "        self.gpu = 2 # set which GPU to use\n",
    "        self.seed = 1 # random seed (default: 1)\n",
    "        self.log_interval = 10 # how many batches to wait before logging training status\n",
    "        self.shift_test = True\n",
    "        self.train_shift_per_class = 20\n",
    "        \n",
    "opt = Options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_shift_per_class=0):\n",
    "    ### Prepare Data ###\n",
    "    ####################\n",
    "    mnist_train = datasets.MNIST('./mydata', train=True, download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ]))\n",
    "\n",
    "    idx0_train = mnist_train.train_labels==0\n",
    "    idx0_train_val = idx0_train.nonzero()\n",
    "    idx1_train = mnist_train.train_labels==1\n",
    "    idx1_train_val = idx1_train.nonzero()\n",
    "    idx = idx0_train + idx1_train\n",
    "    mnist_train.train_labels = mnist_train.train_labels[idx]\n",
    "    mnist_train.train_data = mnist_train.train_data[idx]\n",
    "\n",
    "    # partially shift the train set\n",
    "    idx0_train_val = (mnist_train.train_labels==0).nonzero()\n",
    "    idx1_train_val = (mnist_train.train_labels==1).nonzero()\n",
    "    \n",
    "    idx0_train_shift = idx0_train_val[0:train_shift_per_class]\n",
    "    idx0_train_noshift = idx0_train_val[train_shift_per_class:]\n",
    "    idx1_train_shift = idx1_train_val[0:train_shift_per_class]\n",
    "    idx1_train_noshift = idx1_train_val[train_shift_per_class:]\n",
    "    \n",
    "    # bias the training set\n",
    "    mnist_train.train_data[idx0_train_shift] = 255 - mnist_train.train_data[idx0_train_shift]\n",
    "    mnist_train.train_data[idx1_train_shift] = 255 - mnist_train.train_data[idx1_train_shift]\n",
    "\n",
    "    mnist_test = datasets.MNIST('./mydata', train=False,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.1307,), (0.3081,))\n",
    "                           ]))\n",
    "    \n",
    "    # make subsetsampler for 0, shifted 0, 1, and shifted 1\n",
    "    train_0_shift_sampler = SubsetRandomSampler(idx0_train_shift)\n",
    "    train_0_noshift_sampler = SubsetRandomSampler(idx0_train_noshift)\n",
    "    train_1_shift_sampler = SubsetRandomSampler(idx1_train_shift)\n",
    "    train_1_noshift_sampler = SubsetRandomSampler(idx1_train_noshift)\n",
    "    \n",
    "    idx0_test = mnist_test.test_labels==0\n",
    "    idx1_test = mnist_test.test_labels==1\n",
    "    idx = idx0_test + idx1_test\n",
    "    mnist_test.test_labels = mnist_test.test_labels[idx]\n",
    "    mnist_test.test_data = mnist_test.test_data[idx]\n",
    "    if opt.shift_test:\n",
    "        mnist_test.test_data = 255 - mnist_test.test_data\n",
    "    \n",
    "    # create data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=opt.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=opt.test_batch_size, shuffle=True, **kwargs)\n",
    "    train_0_shift_loader = torch.utils.data.DataLoader(mnist_train, batch_size=opt.batch_size, shuffle=True, \n",
    "                                                       sampler=train_0_shift_sampler, **kwargs)\n",
    "    train_0_noshift_loader = torch.utils.data.DataLoader(mnist_train, batch_size=opt.batch_size, shuffle=True, \n",
    "                                                       sampler=train_0_noshift_sampler, **kwargs)\n",
    "    train_1_shift_loader = torch.utils.data.DataLoader(mnist_train, batch_size=opt.batch_size, shuffle=True, \n",
    "                                                       sampler=train_1_shift_sampler, **kwargs)\n",
    "    train_1_noshift_loader = torch.utils.data.DataLoader(mnist_train, batch_size=opt.batch_size, shuffle=True, \n",
    "                                                       sampler=train_1_noshift_sampler, **kwargs)\n",
    "\n",
    "    # Check the number of samples in train and test sets\n",
    "    print('Number of train samples = %i'%len(mnist_train))\n",
    "    print('Number of 0 in train set = %i'%idx0_train.sum())\n",
    "    print('Number of 1 in train set = %i'%idx1_train.sum())\n",
    "    print('Number of test samples = %i'%len(mnist_test))\n",
    "    print('Number of 0 in test set = %i'%idx0_test.sum())\n",
    "    print('Number of 1 in test set = %i'%idx1_test.sum())\n",
    "\n",
    "    # visualize train samples\n",
    "    print('Visualize shifted class 0 train samples')\n",
    "    for i in idx0_train_val[0:3]:\n",
    "        image_i, target_i = mnist_train[i[0]]\n",
    "        print(image_i.max())\n",
    "        print(image_i.min())\n",
    "\n",
    "        plt.imshow(image_i[0], cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    print('Visualize non-shifted class 0 train samples')\n",
    "    for i in idx0_train_val[train_shift_per_class:train_shift_per_class+3]:\n",
    "        image_i, target_i = mnist_train[i[0]]\n",
    "        print(image_i.max())\n",
    "        print(image_i.min())\n",
    "\n",
    "        plt.imshow(image_i[0], cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    print('Visualize shifted class 1 train samples')\n",
    "    for i in idx1_train_val[0:3]:\n",
    "        image_i, target_i = mnist_train[i[0]]\n",
    "        print(image_i.max())\n",
    "        print(image_i.min())\n",
    "\n",
    "        plt.imshow(image_i[0], cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    print('Visualize non-shifted class 1 train samples')\n",
    "    for i in idx1_train_val[train_shift_per_class:train_shift_per_class+3]:\n",
    "        image_i, target_i = mnist_train[i[0]]\n",
    "        print(image_i.max())\n",
    "        print(image_i.min())\n",
    "\n",
    "        plt.imshow(image_i[0], cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    # visualize test samples\n",
    "    print('Visualize test samples')\n",
    "    for i in range(6):\n",
    "        image_i, target_i = mnist_test[i]\n",
    "        print(image_i.max())\n",
    "        print(image_i.min())\n",
    "\n",
    "        plt.imshow(image_i[0], cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "    return train_loader, test_loader, train_0_shift_loader, train_0_noshift_loader, train_1_shift_sampler, train_1_noshift_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cyclegan(train_shift_per_class=0):\n",
    "    use_cuda = not opt.no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(opt.seed)\n",
    "    device = torch.device(opt.gpu if use_cuda else \"cpu\")\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader, test_loader, train_0_shift_loader, train_0_noshift_loader, train_1_shift_sampler, train_1_noshift_loader = prepare_data(train_shift_per_class)\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=opt.lr, momentum=opt.momentum)\n",
    "    \n",
    "    best_test_accu = 0\n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        train(opt, model, device, train_loader, optimizer, epoch)\n",
    "        test_accu = test(opt, model, device, test_loader)\n",
    "        best_test_accu = test_accu if test_accu > best_test_accu else best_test_accu\n",
    "        print('\\nTest set: Best accuracy: ({:.2f}%)\\n'.format(best_test_accu))\n",
    "    \n",
    "    return best_test_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % opt.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.2f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(opt, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accu = 100. * correct / len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        test_accu))\n",
    "    return test_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(train_shift_per_class=0):\n",
    "    use_cuda = not opt.no_cuda and torch.cuda.is_available()\n",
    "    torch.manual_seed(opt.seed)\n",
    "    device = torch.device(opt.gpu if use_cuda else \"cpu\")\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader, test_loader, train_0_shift_loader, train_0_noshift_loader, train_1_shift_sampler, train_1_noshift_loader = prepare_data(train_shift_per_class)\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=opt.lr, momentum=opt.momentum)\n",
    "    \n",
    "    best_test_accu = 0\n",
    "    for epoch in range(1, opt.epochs + 1):\n",
    "        train(opt, model, device, train_loader, optimizer, epoch)\n",
    "        test_accu = test(opt, model, device, test_loader)\n",
    "        best_test_accu = test_accu if test_accu > best_test_accu else best_test_accu\n",
    "        print('\\nTest set: Best accuracy: ({:.2f}%)\\n'.format(best_test_accu))\n",
    "    \n",
    "    return best_test_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu_vec = []\n",
    "for i in [25]:\n",
    "    test_accu = main(i)\n",
    "    accu_vec.append(test_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accu_vec)\n",
    "import time\n",
    "time.sleep(36000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez('test_accu_biased_mnist.npz', num_shifted=[0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,400,600,800,1000], test_accu=accu_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "num_shifted = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,400,600,800,1000]\n",
    "d = {'number of train samples shifted per class': num_shifted[0:21], 'test accuracy': accu_vec[0:21]}\n",
    "pdnumsqr = pd.DataFrame(d)\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "g=sns.lineplot(x='number of train samples shifted per class', y='test accuracy', data=pdnumsqr)\n",
    "fig = g.get_figure()\n",
    "fig.savefig(\"accu_vs_numshift.png\")\n",
    "# g.set(xscale=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
